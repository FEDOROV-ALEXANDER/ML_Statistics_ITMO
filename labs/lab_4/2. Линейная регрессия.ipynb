{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoDgY8LQLuhv"
   },
   "source": [
    "## Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwo3ddTS-SL3"
   },
   "source": [
    "Реализовать класс для работы с линейной регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51di5NLe-Bxm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.linalg import inv, pinv\n",
    "\n",
    "class MyLinearRegression:\n",
    "    def __init__(self, regularization=None, weight_calc='matrix', lambda_1=None, lambda_2=None, \n",
    "                 batch_size=20, learning_rate=0.01, max_iter=5000, early_stopping=0.0001, standardize=True):\n",
    "        if regularization not in [None, 'l1', 'l2', 'l1l2']:\n",
    "            raise TypeError(f\"Параметр regularization не может принимать значение '{regularization}'\")\n",
    "        if weight_calc not in ['matrix', 'gd', 'sgd']:\n",
    "            raise TypeError(f\"Параметр weight_calc не может принимать значение '{weight_calc}'\")\n",
    "        if regularization in ['l1', 'l1l2'] and weight_calc == 'matrix':\n",
    "            raise TypeError(\"При 'l1' или 'l1l2' нельзя использовать параметр 'matrix'\")\n",
    "        if regularization in ['l1', 'l1l2'] and lambda_1 is None:\n",
    "            raise TypeError(f\"Значение коэффициента регулризации l1 не задано\")\n",
    "        if regularization in ['l2', 'l1l2'] and lambda_2 is None:\n",
    "            raise TypeError(f\"Значение коэффициента регулризации l2 не задано\")\n",
    "        \n",
    "        self.regularization = regularization\n",
    "        self.weight_calc = weight_calc\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.early_stopping = early_stopping\n",
    "        self.standardize = standardize\n",
    "        \n",
    "        self.coefs_ = None\n",
    "        self.intercept_ = None\n",
    "        self.scaler_ = None\n",
    "\n",
    "    def _prepare_data(self, X, fit=False):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        X = np.array(X)\n",
    "        \n",
    "        if self.standardize:\n",
    "            if fit:\n",
    "                self.scaler_ = StandardScaler()\n",
    "                X = self.scaler_.fit_transform(X)\n",
    "            else:\n",
    "                if self.scaler_ is None:\n",
    "                    raise ValueError(\"Модель не обучена. Сначала вызовите fit().\")\n",
    "                X = self.scaler_.transform(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def _compute_gradient(self, X, y, weights):\n",
    "        n = X.shape[0]\n",
    "        predictions = X @ weights.reshape(-1, 1)\n",
    "        grad = (2 / n) * X.T @ (predictions - y.reshape(-1, 1))\n",
    "        grad = grad.flatten()\n",
    "        \n",
    "        if self.regularization == 'l1':\n",
    "            grad[1:] += self.lambda_1 * np.sign(weights[1:])\n",
    "        elif self.regularization == 'l2':\n",
    "            grad[1:] += 2 * self.lambda_2 * weights[1:]\n",
    "        elif self.regularization == 'l1l2':\n",
    "            grad[1:] += self.lambda_1 * np.sign(weights[1:]) + 2 * self.lambda_2 * weights[1:]\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def _fit_matrix(self, X, y):\n",
    "        X_with_ones = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        if self.regularization == 'l2':\n",
    "            n_features = X_with_ones.shape[1]\n",
    "            reg_matrix = np.eye(n_features)\n",
    "            reg_matrix[0, 0] = 0\n",
    "            \n",
    "            try:\n",
    "                weights = inv(X_with_ones.T @ X_with_ones + self.lambda_2 * reg_matrix) @ X_with_ones.T @ y\n",
    "            except np.linalg.LinAlgError:\n",
    "                weights = pinv(X_with_ones.T @ X_with_ones + self.lambda_2 * reg_matrix) @ X_with_ones.T @ y\n",
    "        else:\n",
    "            try:\n",
    "                weights = inv(X_with_ones.T @ X_with_ones) @ X_with_ones.T @ y\n",
    "            except np.linalg.LinAlgError:\n",
    "                weights = pinv(X_with_ones.T @ X_with_ones) @ X_with_ones.T @ y\n",
    "        \n",
    "        self.intercept_ = weights[0, 0]\n",
    "        self.coefs_ = weights[1:, 0].reshape(-1, 1)\n",
    "    \n",
    "    def _fit_gd(self, X, y):\n",
    "        X_with_ones = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        weights = np.random.uniform(-0.1, 0.1, size=(X_with_ones.shape[1],))\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            grad = self._compute_gradient(X_with_ones, y, weights)\n",
    "            grad_norm = np.linalg.norm(grad)\n",
    "            \n",
    "            if grad_norm < self.early_stopping:\n",
    "                break\n",
    "            \n",
    "            weights = weights - self.learning_rate * grad\n",
    "        \n",
    "        self.intercept_ = weights[0]\n",
    "        self.coefs_ = weights[1:].reshape(-1, 1)\n",
    "    \n",
    "    def _fit_sgd(self, X, y):\n",
    "        X_with_ones = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        y = y.reshape(-1, 1)\n",
    "        n = X_with_ones.shape[0]\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        weights = np.random.uniform(-0.1, 0.1, size=(X_with_ones.shape[1],))\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            indices = np.random.permutation(n)\n",
    "            X_shuffled = X_with_ones[indices]\n",
    "            y_shuffled = y[indices]\n",
    "            \n",
    "            for j in range(0, n, self.batch_size):\n",
    "                batch_end = min(j + self.batch_size, n)\n",
    "                X_batch = X_shuffled[j:batch_end]\n",
    "                y_batch = y_shuffled[j:batch_end]\n",
    "                \n",
    "                grad = self._compute_gradient(X_batch, y_batch, weights)\n",
    "                grad_norm = np.linalg.norm(grad)\n",
    "                \n",
    "                if grad_norm < self.early_stopping:\n",
    "                    break\n",
    "                \n",
    "                weights = weights - self.learning_rate * grad\n",
    "            \n",
    "            if grad_norm < self.early_stopping:\n",
    "                break\n",
    "        \n",
    "        self.intercept_ = weights[0]\n",
    "        self.coefs_ = weights[1:].reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        X = self._prepare_data(X, fit=True)\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "        y = np.array(y)\n",
    "        \n",
    "        if self.weight_calc == 'matrix':\n",
    "            self._fit_matrix(X, y)\n",
    "        elif self.weight_calc == 'gd':\n",
    "            self._fit_gd(X, y)\n",
    "        elif self.weight_calc == 'sgd':\n",
    "            self._fit_sgd(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X, ss=True):\n",
    "        if self.coefs_ is None or self.intercept_ is None:\n",
    "            raise ValueError(\"Модель не обучена. Сначала вызовите fit().\")\n",
    "        \n",
    "        X = self._prepare_data(X, fit=False)\n",
    "        predictions = X @ self.coefs_ + self.intercept_\n",
    "        return predictions.flatten()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        if self.coefs_ is None or self.intercept_ is None:\n",
    "            raise ValueError(\"Модель не обучена. Сначала вызовите fit().\")\n",
    "        \n",
    "        y_pred = self.predict(X)\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "        y = np.array(y).flatten()\n",
    "        \n",
    "        ss_res = np.sum((y - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        \n",
    "        if ss_tot == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flYIBMseNV2O"
   },
   "source": [
    "Используя датасет про автомобили (целевой признак — price), сравнить (качество, скорость обучения и предсказания, важность признаков) модели `MyLinearRegression` с различными гиперпараметрами, сделать выводы. На этом же датасете сравнить модель `MyLinearRegression` с библиотечной реализацией из `sklearn`, составить таблицу(ы) (графики) результатов сравнения (качество, скорость обучения и предсказания, важность признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKO_QAb5Lmdd"
   },
   "source": [
    "## Задача 2\n",
    "\n",
    "[Соревнование на Kaggle](https://kaggle.com/competitions/yadro-regression-2025)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
