{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDjH5VgLMPCa"
   },
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8T7M9eQMRRn"
   },
   "source": [
    "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение\n",
    "\n",
    "## Оценка MLE\n",
    "\n",
    "Плотность экспоненциального распределения:\n",
    "$$\n",
    "f(x \\mid \\lambda) = \\begin{cases}\n",
    "\\lambda e^{-\\lambda x}, & x \\geq 0 \\\\\n",
    "0, & x < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Функция правдоподобия выборки $\\mathbf{x} = (x_1, \\dots, x_n)$:\n",
    "$$\n",
    "L(\\lambda) = \\prod_{i=1}^{n} f(x_i \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} = \\lambda^n e^{-n\\lambda\\overline{X}},\n",
    "$$\n",
    "где $\\overline{X} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ — выборочное среднее.\n",
    "\n",
    "Логарифмическая функция правдоподобия:\n",
    "$$\n",
    "\\ell(\\lambda) = \\ln L(\\lambda) = n\\ln\\lambda - n\\lambda\\overline{X}\n",
    "$$\n",
    "\n",
    "Находим производную и приравниваем к нулю:\n",
    "$$\n",
    "\\frac{d\\ell}{d\\lambda} = \\frac{n}{\\lambda} - n\\overline{X} = 0\n",
    "$$\n",
    "\n",
    "Откуда получаем оценку максимального правдоподобия:\n",
    "$$\n",
    "\\hat{\\lambda}_{\\text{MLE}} = \\frac{1}{\\overline{X}}\n",
    "$$\n",
    "\n",
    "## Байесовская оценка\n",
    "\n",
    "### Выбор априорного распределения\n",
    "\n",
    "В качестве сопряженного априорного распределения для экспоненциального распределения выбираем гамма-распределение:\n",
    "$$\n",
    "p(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}, \\quad \\lambda > 0, \\quad a > 0, \\quad b > 0\n",
    "$$\n",
    "\n",
    "### Апостериорное распределение\n",
    "\n",
    "По формуле Байеса:\n",
    "$$\n",
    "p(\\lambda \\mid D) = \\frac{p(\\lambda) \\cdot p(D \\mid \\lambda)}{p(D)} = \\frac{p(\\lambda) \\cdot L(\\lambda)}{\\int_0^{+\\infty} p(\\lambda) \\cdot L(\\lambda) d\\lambda}\n",
    "$$\n",
    "\n",
    "Числитель:\n",
    "$$\n",
    "p(\\lambda) \\cdot L(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda} \\cdot \\lambda^n e^{-n\\lambda\\overline{X}} = \\frac{b^a}{\\Gamma(a)}\\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})}\n",
    "$$\n",
    "\n",
    "Знаменатель (нормировочная константа):\n",
    "$$\n",
    "p(D) = \\int_0^{+\\infty} \\frac{b^a}{\\Gamma(a)}\\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})} d\\lambda = \\frac{b^a}{\\Gamma(a)} \\int_0^{+\\infty} \\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})} d\\lambda\n",
    "$$\n",
    "\n",
    "Замена переменной $t = \\lambda(b+n\\overline{X})$, $d\\lambda = \\frac{dt}{b+n\\overline{X}}$:\n",
    "$$\n",
    "\\int_0^{+\\infty} \\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})} d\\lambda = \\int_0^{+\\infty} \\left(\\frac{t}{b+n\\overline{X}}\\right)^{n+a-1} e^{-t} \\frac{dt}{b+n\\overline{X}} = \\frac{1}{(b+n\\overline{X})^{n+a}} \\int_0^{+\\infty} t^{n+a-1} e^{-t} dt = \\frac{\\Gamma(n+a)}{(b+n\\overline{X})^{n+a}}\n",
    "$$\n",
    "\n",
    "Таким образом:\n",
    "$$\n",
    "p(D) = \\frac{b^a}{\\Gamma(a)} \\cdot \\frac{\\Gamma(n+a)}{(b+n\\overline{X})^{n+a}} = \\frac{b^a \\Gamma(n+a)}{\\Gamma(a)(b+n\\overline{X})^{n+a}}\n",
    "$$\n",
    "\n",
    "Апостериорное распределение:\n",
    "$$\n",
    "p(\\lambda \\mid D) = \\frac{\\frac{b^a}{\\Gamma(a)}\\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})}}{\\frac{b^a \\Gamma(n+a)}{\\Gamma(a)(b+n\\overline{X})^{n+a}}} = \\frac{(b+n\\overline{X})^{n+a}}{\\Gamma(n+a)}\\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})}\n",
    "$$\n",
    "\n",
    "Это гамма-распределение с параметрами:\n",
    "- Форма: $a' = n + a$\n",
    "- Масштаб: $b' = b + n\\overline{X}$\n",
    "\n",
    "То есть $\\lambda \\mid D \\sim \\text{Gamma}(n+a, b+n\\overline{X})$.\n",
    "\n",
    "### Математическое ожидание апостериорного распределения\n",
    "\n",
    "Математическое ожидание гамма-распределения $\\text{Gamma}(\\alpha, \\beta)$ равно $\\frac{\\alpha}{\\beta}$.\n",
    "\n",
    "Следовательно:\n",
    "$$\n",
    "\\mathbb{E}[\\lambda \\mid D] = \\frac{n+a}{b+n\\overline{X}}\n",
    "$$\n",
    "\n",
    "### Оценка MAP\n",
    "\n",
    "Мода гамма-распределения $\\text{Gamma}(\\alpha, \\beta)$ при $\\alpha > 1$ равна $\\frac{\\alpha - 1}{\\beta}$.\n",
    "\n",
    "Следовательно:\n",
    "$$\n",
    "\\hat{\\lambda}_{\\text{MAP}} = \\frac{n+a-1}{b+n\\overline{X}}\n",
    "$$\n",
    "\n",
    "### Сравнение оценок\n",
    "\n",
    "**MLE:**\n",
    "$$\n",
    "\\hat{\\lambda}_{\\text{MLE}} = \\frac{1}{\\overline{X}}\n",
    "$$\n",
    "\n",
    "**Математическое ожидание апостериорного распределения:**\n",
    "$$\n",
    "\\mathbb{E}[\\lambda \\mid D] = \\frac{n+a}{b+n\\overline{X}} = \\frac{1}{\\overline{X}} \\cdot \\frac{n+a}{b/\\overline{X} + n}\n",
    "$$\n",
    "\n",
    "**MAP:**\n",
    "$$\n",
    "\\hat{\\lambda}_{\\text{MAP}} = \\frac{n+a-1}{b+n\\overline{X}} = \\frac{1}{\\overline{X}} \\cdot \\frac{n+a-1}{b/\\overline{X} + n}\n",
    "$$\n",
    "\n",
    "**Наблюдения:**\n",
    "- При $n \\to \\infty$ обе байесовские оценки стремятся к MLE: $\\hat{\\lambda}_{\\text{MLE}} = \\frac{1}{\\overline{X}}$\n",
    "- При малых $n$ байесовские оценки учитывают априорную информацию через параметры $a$ и $b$\n",
    "- Если $a = 1$ и $b \\to 0$ (неинформативный априор), то $\\mathbb{E}[\\lambda \\mid D] \\approx \\hat{\\lambda}_{\\text{MLE}}$ и $\\hat{\\lambda}_{\\text{MAP}} \\approx \\hat{\\lambda}_{\\text{MLE}}$\n",
    "- Математическое ожидание всегда больше MAP при $n+a > 1$, так как $\\frac{n+a}{b+n\\overline{X}} > \\frac{n+a-1}{b+n\\overline{X}}$\n",
    "\n",
    "### Предсказательное распределение\n",
    "\n",
    "Предсказательное распределение для нового наблюдения $x_{\\text{new}}$:\n",
    "$$\n",
    "p(x_{\\text{new}} \\mid D) = \\int_0^{+\\infty} p(x_{\\text{new}} \\mid \\lambda) \\cdot p(\\lambda \\mid D) d\\lambda\n",
    "$$\n",
    "\n",
    "Подставляем:\n",
    "$$\n",
    "p(x_{\\text{new}} \\mid D) = \\int_0^{+\\infty} \\lambda e^{-\\lambda x_{\\text{new}}} \\cdot \\frac{(b+n\\overline{X})^{n+a}}{\\Gamma(n+a)}\\lambda^{n+a-1}e^{-\\lambda(b+n\\overline{X})} d\\lambda\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{(b+n\\overline{X})^{n+a}}{\\Gamma(n+a)} \\int_0^{+\\infty} \\lambda^{n+a} e^{-\\lambda(x_{\\text{new}} + b + n\\overline{X})} d\\lambda\n",
    "$$\n",
    "\n",
    "Замена переменной $t = \\lambda(x_{\\text{new}} + b + n\\overline{X})$, $d\\lambda = \\frac{dt}{x_{\\text{new}} + b + n\\overline{X}}$:\n",
    "$$\n",
    "\\int_0^{+\\infty} \\lambda^{n+a} e^{-\\lambda(x_{\\text{new}} + b + n\\overline{X})} d\\lambda = \\int_0^{+\\infty} \\left(\\frac{t}{x_{\\text{new}} + b + n\\overline{X}}\\right)^{n+a} e^{-t} \\frac{dt}{x_{\\text{new}} + b + n\\overline{X}} = \\frac{\\Gamma(n+a+1)}{(x_{\\text{new}} + b + n\\overline{X})^{n+a+1}}\n",
    "$$\n",
    "\n",
    "Таким образом:\n",
    "$$\n",
    "p(x_{\\text{new}} \\mid D) = \\frac{(b+n\\overline{X})^{n+a}}{\\Gamma(n+a)} \\cdot \\frac{\\Gamma(n+a+1)}{(x_{\\text{new}} + b + n\\overline{X})^{n+a+1}} = \\frac{(n+a)(b+n\\overline{X})^{n+a}}{(x_{\\text{new}} + b + n\\overline{X})^{n+a+1}}\n",
    "$$\n",
    "\n",
    "Это распределение Парето II типа (или ломакс-распределение) с параметрами:\n",
    "- Масштаб: $b + n\\overline{X}$\n",
    "- Форма: $n + a$\n",
    "\n",
    "$$\n",
    "p(x_{\\text{new}} \\mid D) = \\frac{(n+a)(b+n\\overline{X})^{n+a}}{(x_{\\text{new}} + b + n\\overline{X})^{n+a+1}}, \\quad x_{\\text{new}} \\geq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WBXJuchMhzE"
   },
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWArd6bMjkD"
   },
   "source": [
    "**Мультиномиальное распределение**\n",
    "\n",
    "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
    "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
    "\n",
    "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
    "\n",
    "$$\n",
    "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
    "$$\n",
    "\n",
    "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
    "\n",
    "$$\\sum_{i=1}^m n_i = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOvNMoSHMrWR"
   },
   "source": [
    "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат.\n",
    "\n",
    "## Правдоподобие\n",
    "\n",
    "Пусть наблюдены данные $D = (n_1, n_2, \\dots, n_m)$, где $n_k$ — число наступлений события $A_k$ в $n$ испытаниях, и $\\sum_{k=1}^{m} n_k = n$.\n",
    "\n",
    "Функция правдоподобия:\n",
    "$$\n",
    "L(\\mathbf{p} \\mid D) = \\frac{n!}{n_1! n_2! \\dots n_m!} p_1^{n_1} p_2^{n_2} \\dots p_m^{n_m} = \\frac{n!}{\\prod_{k=1}^{m} n_k!} \\prod_{k=1}^{m} p_k^{n_k}\n",
    "$$\n",
    "\n",
    "где $\\mathbf{p} = (p_1, p_2, \\dots, p_m)$ — вектор вероятностей, $\\sum_{k=1}^{m} p_k = 1$.\n",
    "\n",
    "## Априорное распределение (Дирихле)\n",
    "\n",
    "Распределение Дирихле с параметрами $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\dots, \\alpha_m)$, где $\\alpha_k > 0$:\n",
    "$$\n",
    "p(\\mathbf{p} \\mid \\boldsymbol{\\alpha}) = \\frac{\\Gamma(\\sum_{k=1}^{m} \\alpha_k)}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k)} \\prod_{k=1}^{m} p_k^{\\alpha_k - 1}, \\quad \\sum_{k=1}^{m} p_k = 1, \\quad p_k \\geq 0\n",
    "$$\n",
    "\n",
    "где $\\alpha_0 = \\sum_{k=1}^{m} \\alpha_k$ — сумма параметров.\n",
    "\n",
    "## Апостериорное распределение\n",
    "\n",
    "По формуле Байеса:\n",
    "$$\n",
    "p(\\mathbf{p} \\mid D, \\boldsymbol{\\alpha}) = \\frac{p(\\mathbf{p} \\mid \\boldsymbol{\\alpha}) \\cdot L(\\mathbf{p} \\mid D)}{p(D \\mid \\boldsymbol{\\alpha})}\n",
    "$$\n",
    "\n",
    "Числитель:\n",
    "$$\n",
    "p(\\mathbf{p} \\mid \\boldsymbol{\\alpha}) \\cdot L(\\mathbf{p} \\mid D) = \\frac{\\Gamma(\\alpha_0)}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k)} \\prod_{k=1}^{m} p_k^{\\alpha_k - 1} \\cdot \\frac{n!}{\\prod_{k=1}^{m} n_k!} \\prod_{k=1}^{m} p_k^{n_k}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\Gamma(\\alpha_0) n!}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k) \\prod_{k=1}^{m} n_k!} \\prod_{k=1}^{m} p_k^{\\alpha_k + n_k - 1}\n",
    "$$\n",
    "\n",
    "Знаменатель (нормировочная константа):\n",
    "$$\n",
    "p(D \\mid \\boldsymbol{\\alpha}) = \\int_{\\Delta^{m-1}} p(\\mathbf{p} \\mid \\boldsymbol{\\alpha}) \\cdot L(\\mathbf{p} \\mid D) d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "где $\\Delta^{m-1}$ — $(m-1)$-мерный симплекс.\n",
    "\n",
    "Используя свойство интеграла Дирихле:\n",
    "$$\n",
    "\\int_{\\Delta^{m-1}} \\prod_{k=1}^{m} p_k^{\\alpha_k + n_k - 1} d\\mathbf{p} = \\frac{\\prod_{k=1}^{m} \\Gamma(\\alpha_k + n_k)}{\\Gamma(\\sum_{k=1}^{m} (\\alpha_k + n_k))} = \\frac{\\prod_{k=1}^{m} \\Gamma(\\alpha_k + n_k)}{\\Gamma(\\alpha_0 + n)}\n",
    "$$\n",
    "\n",
    "Таким образом:\n",
    "$$\n",
    "p(D \\mid \\boldsymbol{\\alpha}) = \\frac{\\Gamma(\\alpha_0) n!}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k) \\prod_{k=1}^{m} n_k!} \\cdot \\frac{\\prod_{k=1}^{m} \\Gamma(\\alpha_k + n_k)}{\\Gamma(\\alpha_0 + n)}\n",
    "$$\n",
    "\n",
    "Апостериорное распределение:\n",
    "$$\n",
    "p(\\mathbf{p} \\mid D, \\boldsymbol{\\alpha}) = \\frac{\\frac{\\Gamma(\\alpha_0) n!}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k) \\prod_{k=1}^{m} n_k!} \\prod_{k=1}^{m} p_k^{\\alpha_k + n_k - 1}}{\\frac{\\Gamma(\\alpha_0) n!}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k) \\prod_{k=1}^{m} n_k!} \\cdot \\frac{\\prod_{k=1}^{m} \\Gamma(\\alpha_k + n_k)}{\\Gamma(\\alpha_0 + n)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\Gamma(\\alpha_0 + n)}{\\prod_{k=1}^{m} \\Gamma(\\alpha_k + n_k)} \\prod_{k=1}^{m} p_k^{\\alpha_k + n_k - 1}\n",
    "$$\n",
    "\n",
    "Это распределение Дирихле с обновленными параметрами:\n",
    "$$\n",
    "\\mathbf{p} \\mid D, \\boldsymbol{\\alpha} \\sim \\text{Dirichlet}(\\alpha_1 + n_1, \\alpha_2 + n_2, \\dots, \\alpha_m + n_m)\n",
    "$$\n",
    "\n",
    "## Предсказательное распределение\n",
    "\n",
    "Предсказательное распределение для нового наблюдения $x_{\\text{new}} \\in \\{1, 2, \\dots, m\\}$ (индекс категории):\n",
    "$$\n",
    "p(x_{\\text{new}} = k \\mid D, \\boldsymbol{\\alpha}) = \\int_{\\Delta^{m-1}} p(x_{\\text{new}} = k \\mid \\mathbf{p}) \\cdot p(\\mathbf{p} \\mid D, \\boldsymbol{\\alpha}) d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\int_{\\Delta^{m-1}} p_k \\cdot \\frac{\\Gamma(\\alpha_0 + n)}{\\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)} \\prod_{j=1}^{m} p_j^{\\alpha_j + n_j - 1} d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\Gamma(\\alpha_0 + n)}{\\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)} \\int_{\\Delta^{m-1}} p_k \\prod_{j=1}^{m} p_j^{\\alpha_j + n_j - 1} d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\Gamma(\\alpha_0 + n)}{\\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)} \\int_{\\Delta^{m-1}} p_k^{(\\alpha_k + n_k + 1) - 1} \\prod_{j \\neq k} p_j^{\\alpha_j + n_j - 1} d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "Используя свойство интеграла Дирихле:\n",
    "$$\n",
    "\\int_{\\Delta^{m-1}} p_k^{(\\alpha_k + n_k + 1) - 1} \\prod_{j \\neq k} p_j^{\\alpha_j + n_j - 1} d\\mathbf{p} = \\frac{\\Gamma(\\alpha_k + n_k + 1) \\prod_{j \\neq k} \\Gamma(\\alpha_j + n_j)}{\\Gamma(\\alpha_0 + n + 1)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{(\\alpha_k + n_k) \\Gamma(\\alpha_k + n_k) \\prod_{j \\neq k} \\Gamma(\\alpha_j + n_j)}{\\Gamma(\\alpha_0 + n + 1)} = \\frac{(\\alpha_k + n_k) \\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)}{\\Gamma(\\alpha_0 + n + 1)}\n",
    "$$\n",
    "\n",
    "Таким образом:\n",
    "$$\n",
    "p(x_{\\text{new}} = k \\mid D, \\boldsymbol{\\alpha}) = \\frac{\\Gamma(\\alpha_0 + n)}{\\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)} \\cdot \\frac{(\\alpha_k + n_k) \\prod_{j=1}^{m} \\Gamma(\\alpha_j + n_j)}{\\Gamma(\\alpha_0 + n + 1)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\alpha_k + n_k}{\\alpha_0 + n}\n",
    "$$\n",
    "\n",
    "## Объяснение результата\n",
    "\n",
    "**Апостериорное распределение:**\n",
    "- Параметры Дирихле обновляются простым сложением: $\\alpha_k' = \\alpha_k + n_k$\n",
    "- Априорные параметры $\\alpha_k$ можно интерпретировать как \"псевдонаблюдения\" категории $k$\n",
    "- Сумма параметров обновляется: $\\alpha_0' = \\alpha_0 + n$\n",
    "\n",
    "**Предсказательное распределение:**\n",
    "- Вероятность наблюдения категории $k$ равна $\\frac{\\alpha_k + n_k}{\\alpha_0 + n}$\n",
    "- Это взвешенное среднее между априорной вероятностью $\\frac{\\alpha_k}{\\alpha_0}$ и эмпирической частотой $\\frac{n_k}{n}$\n",
    "- При $n \\to \\infty$ предсказательное распределение стремится к эмпирическим частотам\n",
    "- При малых $n$ большее влияние оказывает априорное распределение\n",
    "\n",
    "**Интерпретация параметров:**\n",
    "- Если все $\\alpha_k = 1$ (равномерный априор), то $p(x_{\\text{new}} = k \\mid D) = \\frac{1 + n_k}{m + n}$ — сглаженная эмпирическая частота\n",
    "- Если $\\alpha_k = \\alpha$ для всех $k$ (симметричный априор), то априорное распределение симметрично относительно всех категорий\n",
    "- Чем больше $\\alpha_0 = \\sum \\alpha_k$, тем \"сильнее\" априор и тем медленнее обновление при поступлении новых данных"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
